{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "import os\n",
    "import numpy as np\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "from datetime import timedelta, date, datetime\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGeopandas():    \n",
    "    shapefile = 'data/countries_110m/ne_110m_admin_0_countries.shp'\n",
    "    gdf = gpd.read_file(shapefile)[['ADMIN', 'ADM0_A3', 'geometry']]\n",
    "    gdf.head()\n",
    "    gdf.columns = ['country', 'country_code', 'geometry']\n",
    "    gdf.head()\n",
    "    \n",
    "    print(gdf[gdf['country'] == 'Antarctica'])\n",
    "    #Drop row corresponding to 'Antarctica'\n",
    "    gdf = gdf.drop(gdf.index[159])\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data from CSSEGISandData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_population = False # swicth it on when want to normalise by population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeSeries(fname):\n",
    "    print(fname)\n",
    "    df = pd.read_csv(fname)\n",
    "    countryData = df.groupby('Country/Region').sum()\n",
    "    countryData = countryData.drop([ 'Lat', 'Long'], axis=1)\n",
    "    return countryData.T\n",
    "    \n",
    "def fetchCountryData(freq='1d'):\n",
    "    gisandata ='https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_'\n",
    "    confirmed = getTimeSeries(f'{gisandata}confirmed_global.csv')\n",
    "    return confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_strdate(val):\n",
    "    mounth = val.strftime(\"%m\")\n",
    "    day = val.strftime(\"%d\")\n",
    "    yer = val.strftime(\"%y\")\n",
    "    \n",
    "    if mounth[0] == '0':\n",
    "        mounth = mounth[1]\n",
    "    if day[0] == '0':\n",
    "        day = day[1]\n",
    "    return '/'.join([mounth,day, yer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from countryinfo import CountryInfo\n",
    "import pycountry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        country country_code  \\\n",
      "159  Antarctica          ATA   \n",
      "\n",
      "                                              geometry  \n",
      "159  MULTIPOLYGON (((-48.66062 -78.04702, -48.15140...  \n",
      "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\n"
     ]
    }
   ],
   "source": [
    "# Load all datas\n",
    "gdf = loadGeopandas()\n",
    "\n",
    "data = fetchCountryData()\n",
    "data = data.rename(columns={'Country/Region': 'country_region'})\n",
    "countries_code = pd.read_csv('JohnsHopkins-to-A3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = []\n",
    "missing_pop = []\n",
    "\n",
    "df = pd.read_csv('population.csv')\n",
    "for i, row in countries_code.iterrows():\n",
    "    a3 = row['alpha3']\n",
    "    p = df[(df['Code']==a3) &( df['Year']=='2019')]['Population']\n",
    "    try:\n",
    "        pop.append(p.values[0])\n",
    "    except IndexError:\n",
    "        pop.append(1)\n",
    "        missing_pop.append(a3)\n",
    "# print(pop)\n",
    "countries_code['population'] = pop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mergegdf_bydate(dateval, norm=False):\n",
    "    # dateval as str\n",
    "\n",
    "    max_conf_bydate = 0\n",
    "    min_conf_bydate = 10\n",
    "    # tmp_df = data[[r'Country/Region', dateval]].copy()\n",
    "    tmp_df = data.loc[dateval]\n",
    "    # tmp_df = tmp_df.rename(columns={dateval: 'confirmed'})\n",
    "    tmp_df_code = pd.merge(countries_code, tmp_df, on='Country/Region')\n",
    "\n",
    "    tmp_df_code[dateval] = pd.to_numeric(tmp_df_code[dateval], downcast=\"float\")\n",
    "    if norm:  # if to normalise to population\n",
    "        for i, row in tmp_df_code.iterrows():\n",
    "            val_percap = float(row[dateval]) / float(row['population'])\n",
    "            if row['population'] > 1 and row[dateval] >0:\n",
    "                if val_percap > max_conf_bydate:\n",
    "                    max_conf_bydate = val_percap\n",
    "                if val_percap < min_conf_bydate:\n",
    "                    min_conf_bydate = val_percap\n",
    "            if row['population'] == 1:\n",
    "                val_percap = 0.\n",
    "            tmp_df_code.at[i, dateval] = val_percap\n",
    "    else:\n",
    "        max_conf_bydate = max(tmp_df_code[dateval])\n",
    "    merged = gdf.merge(tmp_df_code, left_on='country_code', right_on='alpha3', how='left')\n",
    "    merged = merged.rename({'Country/Region': 'country'})\n",
    "\n",
    "    #     merged.fillna(0, inplace = True)\n",
    "    return merged, (min_conf_bydate, max_conf_bydate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max():\n",
    "    yesterday  = datetime.date(datetime.now()-timedelta(1))\n",
    "    _, maxconf = mergegdf_bydate(get_strdate(yesterday))\n",
    "    return maxconf[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gif(odir, start, end, images):\n",
    "    exportname = '{}/map_{}_{}_2.gif'.format(odir, start, end)\n",
    "    kargs = { 'duration': 0.7 }\n",
    "    imageio.mimsave(exportname, images[::2], 'GIF', **kargs)\n",
    "\n",
    "    print('Checkout your new gif', exportname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_imgs(single_date, fname, range, norm=False):\n",
    "    date = get_strdate(single_date)\n",
    "    merged,_ = mergegdf_bydate(date, norm)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(20, 12))\n",
    "\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"2.5%\", pad=0.01)\n",
    "\n",
    "    title = 'COVID-19 cases on {}'.format(single_date)\n",
    "    cz_label = 'Number of confirmed cases'\n",
    "    cm = 'inferno_r'\n",
    "    if norm_by_pop:\n",
    "        title = 'COVID-19 cases per capita on {}'.format(single_date)\n",
    "        cz_label = 'N. of confirmed cases per capita'\n",
    "        cm = 'viridis_r'\n",
    "    merged.plot(column=date, cmap=cm,\n",
    "                linewidth=0.6, ax=ax, edgecolor='0.8',\n",
    "                legend=True,\n",
    "                norm=colors.LogNorm(vmin=range[0], vmax=range[1]),\n",
    "                cax=cax)\n",
    "\n",
    "    ax.axis('off')\n",
    "\n",
    "    ax.text(0.3, 1.1, title,\n",
    "            fontdict={'fontsize': 25, 'fontweight': '3'},\n",
    "            transform=ax.transAxes)\n",
    "\n",
    "    ax.annotate('Source: CSSEGISandData', xy=(0.1, .1),\n",
    "                xycoords='figure fraction', horizontalalignment='left',\n",
    "                verticalalignment='top', fontsize=12, color='#555555')\n",
    "\n",
    "    ax.annotate('Copyright: RizM', xy=(0.1, .05),\n",
    "                xycoords='figure fraction', horizontalalignment='left',\n",
    "                verticalalignment='top', fontsize=12, color='#555555')\n",
    "\n",
    "    cax.tick_params(labelsize=18)\n",
    "    cax.set_ylabel(cz_label, fontsize=18)\n",
    "    #     cax.labelsize=18)\n",
    "    odir = fname.split('/')[0]\n",
    "    os.makedirs(odir, exist_ok=True)\n",
    "    fig.savefig(fname)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get csv with the countries and alpha codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def minMax(drange):\n",
    "\n",
    "    min_percapita = 10\n",
    "    max_percapita = 0\n",
    "    for d in drange:\n",
    "        dt = get_strdate(d)\n",
    "        _, range = mergegdf_bydate(dt, True)\n",
    "        if  range[0] < min_percapita and range[0]>0:\n",
    "            min_percapita = range[0]\n",
    "\n",
    "        if range[1] > max_percapita:\n",
    "            max_percapita = range[1]\n",
    "    return (min_percapita, max_percapita)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-22\n",
      "2020-01-23\n",
      "2020-01-24\n",
      "2020-01-25\n",
      "2020-01-26\n",
      "2020-01-27\n",
      "2020-01-28\n",
      "2020-01-29\n",
      "2020-01-30\n",
      "2020-01-31\n",
      "2020-02-01\n",
      "2020-02-02\n",
      "2020-02-03\n",
      "2020-02-04\n",
      "2020-02-05\n",
      "2020-02-06\n",
      "2020-02-07\n",
      "2020-02-08\n",
      "2020-02-09\n",
      "2020-02-10\n",
      "2020-02-11\n",
      "2020-02-12\n",
      "2020-02-13\n",
      "2020-02-14\n",
      "2020-02-15\n",
      "2020-02-16\n",
      "2020-02-17\n",
      "2020-02-18\n",
      "2020-02-19\n",
      "2020-02-20\n",
      "2020-02-21\n",
      "2020-02-22\n",
      "2020-02-23\n",
      "2020-02-24\n",
      "2020-02-25\n",
      "2020-02-26\n",
      "2020-02-27\n",
      "2020-02-28\n",
      "2020-02-29\n",
      "2020-03-01\n",
      "2020-03-02\n",
      "2020-03-03\n",
      "2020-03-04\n",
      "2020-03-05\n",
      "2020-03-06\n",
      "2020-03-07\n",
      "2020-03-08\n",
      "2020-03-09\n",
      "2020-03-10\n",
      "2020-03-11\n",
      "2020-03-12\n",
      "2020-03-13\n",
      "2020-03-14\n",
      "2020-03-15\n",
      "2020-03-16\n",
      "2020-03-17\n",
      "2020-03-18\n",
      "2020-03-19\n",
      "2020-03-20\n",
      "2020-03-21\n",
      "2020-03-22\n",
      "2020-03-23\n",
      "2020-03-24\n",
      "2020-03-25\n",
      "2020-03-26\n",
      "2020-03-27\n",
      "2020-03-28\n",
      "2020-03-29\n",
      "2020-03-30\n",
      "2020-03-31\n",
      "2020-04-01\n",
      "2020-04-02\n",
      "2020-04-03\n",
      "2020-04-04\n",
      "2020-04-05\n",
      "2020-04-06\n",
      "2020-04-07\n",
      "2020-04-08\n",
      "2020-04-09\n",
      "2020-04-10\n",
      "2020-04-11\n",
      "2020-04-12\n",
      "2020-04-13\n",
      "2020-04-14\n",
      "2020-04-15\n",
      "2020-04-16\n",
      "2020-04-17\n",
      "2020-04-18\n",
      "2020-04-19\n",
      "2020-04-20\n",
      "2020-04-21\n",
      "2020-04-22\n",
      "2020-04-23\n",
      "2020-04-24\n",
      "2020-04-25\n",
      "2020-04-26\n",
      "2020-04-27\n",
      "2020-04-28\n",
      "2020-04-29\n",
      "2020-04-30\n",
      "2020-05-01\n",
      "2020-05-02\n",
      "Checkout your new gif covid_map/map_2020-01-22_2020-05-03_2.gif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def daterange(start_date, end_date):\n",
    "    drange = []\n",
    "    for n in range(int((end_date - start_date).days)):\n",
    "        drange.append(start_date + timedelta(n))\n",
    "    return drange\n",
    "\n",
    "\n",
    "\n",
    "today = datetime.date(datetime.now())\n",
    "start = date(2020, 1, 22)\n",
    "end = date(2020, 1, 30)\n",
    "\n",
    "drange = daterange(start,today)\n",
    "images = []\n",
    "# '''\n",
    "norm_by_pop = False\n",
    "\n",
    "if norm_by_pop:\n",
    "    range = minMax(drange)\n",
    "else:\n",
    "    range=(1,  get_max())\n",
    "\n",
    "for single_date in drange:\n",
    "    odir = 'covid_map'\n",
    "    if norm_by_pop:\n",
    "        odir = 'covid_map_percapita'\n",
    "    fname = f'{odir}/{single_date.strftime(\"%d_%m_%Y\")}.png'\n",
    "\n",
    "    print(single_date)\n",
    "    create_imgs(single_date, fname, range, norm_by_pop)\n",
    "\n",
    "    images.append(imageio.imread(fname))\n",
    "\n",
    "create_gif(odir, start, today, images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<br>\n",
    "import qgrid<br>\n",
    "qgrid_w = qgrid.show_grid(tmp_df, show_toolbar = True)<br>\n",
    "qgrid_w<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qqgrid)",
   "language": "python",
   "name": "qqgrid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
